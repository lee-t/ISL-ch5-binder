{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/lee-t/ISL-ch5-jupyterlite/HEAD?urlpath=%2Fdoc%2Ftree%2Fcontent%2FCh05-resample-lab.ipynb) \n",
    "Resampling methods are an indispensable tool in modern statistics. They\n",
    "involve repeatedly drawing samples from a training set and refitting a model\n",
    "of interest on each sample in order to obtain additional information about\n",
    "the fitted model. For example, in order to estimate the variability of a linear\n",
    "regression fit, we can repeatedly draw different samples from the training\n",
    "data, fit a linear regression to each new sample, and then examine the\n",
    "extent to which the resulting fits differ. Such an approach may allow us to\n",
    "obtain information that would not be available from fitting the model only\n",
    "once using the original training sample.\n",
    "\n",
    "In this chapter, we discuss two of the most commonly\n",
    "used resampling methods, *cross-validation* and the *bootstrap*.\n",
    "\n",
    "Cross-validation is most often used to estimate test error associated with a statistical learning method, whereas the bootstrap is most commonly used to provide a measure of accuracy for a given parameter/method.\n",
    "\n",
    "The process\n",
    "of evaluating a model's performance is known as *model assessment*, whereas \n",
    "the process of selecting the proper level of flexibility for a model is known as *model selection*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ISLP import load_data\n",
    "from sklearn.model_selection import train_test_split, KFold, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style='whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Sometimes we want to estimate the test error rate using the available training data.\n",
    "A number of approaches can be used for this.\n",
    "In this section we consider methods which involve *holding out* a subset of the training data from the fitting process, then applying the model to that hold-out set for model assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Validation Set Approach\n",
    "\n",
    "This simple strategy involves randomly dividing available observations into training and validation sets.\n",
    "The model is fit on the training set, and used to make predictions on the validation set.\n",
    "The corresponding metric from the validation set predictions -- usually MSE in the case of a quantitative response -- provides an estimate of the test error rate.\n",
    "\n",
    "Load the `Auto` data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Auto dataset\n",
    "Auto = load_data('Auto')\n",
    "Auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly split the data into 50% training and 50% validation, fit on the training set, and compute the MSE on the validation set.\n",
    "We'll repeat this 10 times to reproduce a figure similar to Figure 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_poly_models(X_train, X_test, y_train, y_test, max_degree=10):\n",
    "    \"\"\"Evaluate polynomial models of different degrees.\"\"\"\n",
    "    mse_values = []\n",
    "    for degree in range(1, max_degree + 1):\n",
    "        # Create polynomial features\n",
    "        poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "        X_train_poly = poly_features.fit_transform(X_train.reshape(-1, 1))\n",
    "        X_test_poly = poly_features.transform(X_test.reshape(-1, 1))\n",
    "        \n",
    "        # Fit linear regression\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_poly, y_train)\n",
    "        \n",
    "        # Predict and calculate MSE\n",
    "        y_pred = model.predict(X_test_poly)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_values.append(mse)\n",
    "    \n",
    "    return mse_values\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(10)\n",
    "\n",
    "# Prepare data\n",
    "X = Auto['horsepower'].values\n",
    "y = Auto['mpg'].values\n",
    "\n",
    "# Single split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=10)\n",
    "mse_single = evaluate_poly_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"MSE for different polynomial degrees (single split):\")\n",
    "for i, mse in enumerate(mse_single[:3], 1):\n",
    "    print(f\"Degree {i}: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat validation split approach 10 times\n",
    "all_mse = {}\n",
    "for i in range(1, 11):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=i)\n",
    "    mse_values = evaluate_poly_models(X_train, X_test, y_train, y_test)\n",
    "    all_mse[i] = mse_values\n",
    "\n",
    "# Plot results (similar to Figure 5.2)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left panel: single split\n",
    "degrees = range(1, 11)\n",
    "ax1.plot(degrees, all_mse[1], marker='o', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Degree of polynomial')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.set_ylim([15, 30])\n",
    "ax1.set_title('Single Validation Split')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Right panel: multiple splits\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "for i, color in enumerate(all_mse.keys(), 1):\n",
    "    ax2.plot(degrees, all_mse[i], linewidth=1.5, alpha=0.7, color=colors[i-1])\n",
    "ax2.set_xlabel('Degree of polynomial')\n",
    "ax2.set_ylabel('MSE')\n",
    "ax2.set_ylim([15, 30])\n",
    "ax2.set_title('Multiple Validation Splits')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is clear from the right-hand panel, this approach is highly variable depending on the testing/validation set split.\n",
    "Another downside is that, because the training set used to fit the data has fewer observations, it tends to overestimate the test error rate on the entire data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross Validation (LOOCV)\n",
    "\n",
    "*Leave-one-out cross validation* (LOOCV) attempts to address the shortcomings of the validation set approach.\n",
    "It still involves splitting the $n$ observations into two parts, but it repeats it $n$ times, with a single observation $(x_i, y_i)$ as the hold-out \"set\" and the remaining $n-1$ observations as the training set.\n",
    "The MSE for each iteration is simply $\\text{MSE}_i = (y_i - \\hat{y}_i)^2$.\n",
    "Then the LOOCV estimate of the MSE is the average over all observations:\n",
    "\n",
    "$$\n",
    "\\text{CV}_{(n)} = \\frac{1}{n} \\sum_{i=1}^n \\text{MSE}_i.\n",
    "$$\n",
    "\n",
    "The LOOCV approach has advantages over the validation set approach:\n",
    "- First, it has far less bias since we use training sets with $n - 1$ observations.\n",
    "- Second, it yields deterministic results (no randomness in splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOCV for polynomial regression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "def loocv_mse(X, y, degree):\n",
    "    \"\"\"Calculate LOOCV MSE for a polynomial model.\"\"\"\n",
    "    loo = LeaveOneOut()\n",
    "    mse_scores = []\n",
    "    \n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly_features.fit_transform(X.reshape(-1, 1))\n",
    "    \n",
    "    for train_idx, test_idx in loo.split(X_poly):\n",
    "        X_train, X_test = X_poly[train_idx], X_poly[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_scores.append((y_test[0] - y_pred[0])**2)\n",
    "    \n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "# Calculate LOOCV MSE for degrees 1-10\n",
    "# Note: This can be slow for large datasets\n",
    "print(\"Computing LOOCV MSE (this may take a moment)...\")\n",
    "loocv_mse_values = [loocv_mse(X, y, degree) for degree in range(1, 11)]\n",
    "\n",
    "print(\"\\nLOOCV MSE for different polynomial degrees:\")\n",
    "for i, mse in enumerate(loocv_mse_values, 1):\n",
    "    print(f\"Degree {i}: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-fold Cross-Validation\n",
    "\n",
    "*$k$-fold CV* involves randomly dividing the observations into $k$ groups/folds of approximately equal size.\n",
    "The first fold is used as the validation/assessment set, and the remaining $k-1$ folds used to fit the model.\n",
    "This is repeated $k$ times, with each fold being used as the assessment set once.\n",
    "The $k$-fold CV estimate of the test error is then the average:\n",
    "\n",
    "$$\n",
    "\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{i=1}^k \\text{MSE}_i.\n",
    "$$\n",
    "\n",
    "LOOCV is a special case of $k$-fold CV where $k = n$. In practice, one typically performs $k$-fold CV using $k$ = 5\n",
    "or $k$ = 10. The advantage is computational: LOOCV requires fitting the model $n$ times, while 10-fold\n",
    "CV requires only ten fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation\n",
    "def kfold_cv_mse(X, y, degree, k=10, random_state=10):\n",
    "    \"\"\"Calculate k-fold CV MSE for a polynomial model.\"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    mse_scores = []\n",
    "    \n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly_features.fit_transform(X.reshape(-1, 1))\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(X_poly):\n",
    "        X_train, X_test = X_poly[train_idx], X_poly[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "# Calculate 10-fold CV MSE for degrees 1-10\n",
    "kfold_mse_values = [kfold_cv_mse(X, y, degree) for degree in range(1, 11)]\n",
    "\n",
    "print(\"10-fold CV MSE for different polynomial degrees:\")\n",
    "for i, mse in enumerate(kfold_mse_values, 1):\n",
    "    print(f\"Degree {i}: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 10-fold CV with different random seeds and plot\n",
    "all_kfold_mse = {}\n",
    "for seed in range(1, 11):\n",
    "    mse_values = [kfold_cv_mse(X, y, degree, random_state=seed) for degree in range(1, 11)]\n",
    "    all_kfold_mse[seed] = mse_values\n",
    "\n",
    "# Plot results (similar to Figure 5.4)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left panel: LOOCV (deterministic)\n",
    "degrees = range(1, 11)\n",
    "ax1.plot(degrees, loocv_mse_values, marker='o', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Degree of polynomial')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.set_ylim([15, 30])\n",
    "ax1.set_title('LOOCV')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Right panel: 10-fold CV (multiple runs)\n",
    "degrees = range(1, 11)\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "for i, color in enumerate(all_kfold_mse.keys(), 1):\n",
    "    ax2.plot(degrees, all_kfold_mse[i], linewidth=1.5, alpha=0.7, color=colors[i-1])\n",
    "ax2.set_xlabel('Degree of polynomial')\n",
    "ax2.set_ylabel('MSE')\n",
    "ax2.set_ylim([15, 30])\n",
    "ax2.set_title('10-fold CV (Multiple Runs)')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $k$-fold CV approach (right panel) still has some variability due to random splitting, but much less than the validation set approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bootstrap\n",
    "\n",
    "The *bootstrap* is a widely applicable and extremely powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method. As a simple example, the bootstrap can be used to estimate the standard errors of the coefficients from a linear regression fit.\n",
    "\n",
    "The toy example in this section is about investment in two assets $X$ and $Y$.\n",
    "We wish to choose a fraction $\\alpha$ of investment into $X$ which minimizes the total variance (risk) of the investment.\n",
    "It can be shown that the optimal value is given by:\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{\\sigma_Y^2 - \\sigma_{XY}}{\\sigma_X^2 + \\sigma_Y^2 - 2\\sigma_{XY}},\n",
    "$$\n",
    "\n",
    "where $\\sigma_X^2 = \\text{Var}(X)$, $\\sigma_Y^2 = \\text{Var}(Y)$, and $\\sigma_{XY} = \\text{Cov}(X, Y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Portfolio data\n",
    "Portfolio = load_data('Portfolio')\n",
    "Portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute alpha\n",
    "def alpha_func(X, Y):\n",
    "    \"\"\"Compute the optimal alpha for portfolio allocation.\"\"\"\n",
    "    return ((np.var(Y) - np.cov(X, Y)[0, 1]) / \n",
    "            (np.var(X) + np.var(Y) - 2 * np.cov(X, Y)[0, 1]))\n",
    "\n",
    "# Compute alpha from the full dataset\n",
    "alpha_hat = alpha_func(Portfolio['X'], Portfolio['Y'])\n",
    "print(f\"Estimated alpha: {alpha_hat:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap to estimate standard error of alpha\n",
    "def bootstrap_alpha(data, n_bootstrap=1000, random_state=319):\n",
    "    \"\"\"Perform bootstrap resampling to estimate SE of alpha.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n = len(data)\n",
    "    alpha_estimates = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        X_boot = data['X'].iloc[idx]\n",
    "        Y_boot = data['Y'].iloc[idx]\n",
    "        alpha_estimates.append(alpha_func(X_boot, Y_boot))\n",
    "    \n",
    "    return np.array(alpha_estimates)\n",
    "\n",
    "# Perform bootstrap\n",
    "alpha_boot = bootstrap_alpha(Portfolio, n_bootstrap=1000)\n",
    "\n",
    "print(f\"Bootstrap mean of alpha: {np.mean(alpha_boot):.3f}\")\n",
    "print(f\"Bootstrap SE of alpha: {np.std(alpha_boot):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bootstrap distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(alpha_boot, bins=30, edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(alpha_hat, color='red', linestyle='--', linewidth=2, label=f'Original estimate: {alpha_hat:.3f}')\n",
    "ax1.set_xlabel('Alpha')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Bootstrap Distribution of Alpha')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplot\n",
    "ax2.boxplot(alpha_boot, vert=True)\n",
    "ax2.axhline(alpha_hat, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_ylabel('Alpha')\n",
    "ax2.set_title('Bootstrap Distribution (Boxplot)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Linear Regression Model\n",
    "\n",
    "The bootstrap approach can be used to assess the variability of the coefficient estimates from a statistical learning method. Here we use the bootstrap to assess the variability of the estimates for $\\beta_0$ and $\\beta_1$, the intercept and slope terms for the linear regression model that uses horsepower to predict mpg in the `Auto` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_auto = Auto[['horsepower']]\n",
    "y_auto = Auto['mpg']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_auto, y_auto)\n",
    "\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")\n",
    "print(f\"Coefficient: {model.coef_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap for regression coefficients\n",
    "def bootstrap_regression(X, y, n_bootstrap=1000, random_state=42):\n",
    "    \"\"\"Perform bootstrap to estimate SE of regression coefficients.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n = len(X)\n",
    "    intercepts = []\n",
    "    coefs = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        X_boot = X.iloc[idx]\n",
    "        y_boot = y.iloc[idx]\n",
    "        \n",
    "        model_boot = LinearRegression()\n",
    "        model_boot.fit(X_boot, y_boot)\n",
    "        \n",
    "        intercepts.append(model_boot.intercept_)\n",
    "        coefs.append(model_boot.coef_[0])\n",
    "    \n",
    "    return np.array(intercepts), np.array(coefs)\n",
    "\n",
    "# Perform bootstrap\n",
    "boot_intercepts, boot_coefs = bootstrap_regression(X_auto, y_auto)\n",
    "\n",
    "print(\"Bootstrap estimates:\")\n",
    "print(f\"Intercept - Mean: {np.mean(boot_intercepts):.4f}, SE: {np.std(boot_intercepts):.4f}\")\n",
    "print(f\"Coefficient - Mean: {np.mean(boot_coefs):.4f}, SE: {np.std(boot_coefs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Model Bootstrap\n",
    "\n",
    "We can find better correspondence between bootstrap and regression estimates if we use the quadratic model because it better fits the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap for quadratic regression\n",
    "def bootstrap_quad_regression(X, y, n_bootstrap=1000, random_state=42):\n",
    "    \"\"\"Perform bootstrap for quadratic regression.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n = len(X)\n",
    "    coef_results = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        X_boot = X.iloc[idx]\n",
    "        y_boot = y.iloc[idx]\n",
    "        \n",
    "        # Create quadratic features\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "        X_boot_poly = poly.fit_transform(X_boot)\n",
    "        \n",
    "        model_boot = LinearRegression(fit_intercept=False)\n",
    "        model_boot.fit(X_boot_poly, y_boot)\n",
    "        \n",
    "        coef_results.append(model_boot.coef_)\n",
    "    \n",
    "    return np.array(coef_results)\n",
    "\n",
    "# Perform bootstrap for quadratic model\n",
    "boot_quad_coefs = bootstrap_quad_regression(X_auto, y_auto)\n",
    "\n",
    "print(\"Bootstrap estimates for quadratic model:\")\n",
    "print(f\"Intercept - Mean: {np.mean(boot_quad_coefs[:, 0]):.4f}, SE: {np.std(boot_quad_coefs[:, 0]):.4f}\")\n",
    "print(f\"Linear term - Mean: {np.mean(boot_quad_coefs[:, 1]):.4f}, SE: {np.std(boot_quad_coefs[:, 1]):.4f}\")\n",
    "print(f\"Quadratic term - Mean: {np.mean(boot_quad_coefs[:, 2]):.4f}, SE: {np.std(boot_quad_coefs[:, 2]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we explored:\n",
    "- **Validation Set Approach**: Simple but highly variable\n",
    "- **LOOCV**: Less bias but computationally expensive\n",
    "- **k-fold Cross-Validation**: Good balance of bias-variance tradeoff\n",
    "- **Bootstrap**: Powerful tool for estimating standard errors and uncertainty\n",
    "\n",
    "These resampling methods are fundamental tools in statistical learning for model assessment and selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
